{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EPFL Vaccine Tweet Remove Duplicates",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peregilk/VACMA/blob/master/EPFL_Vaccine_Tweet_Remove_Duplicates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA4moo4dpLBr",
        "colab_type": "text"
      },
      "source": [
        "# Vaccine Tweet Remove Duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDzbq-_JP7M2",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Initiate and Load the Data from Google Sheet\n",
        "#@markdown To run this script you will need a Google sheet with all the tweets that needs to be preprocessed. \n",
        "\n",
        "!pip install --upgrade --quiet gspread\n",
        "import os, sys, glob\n",
        "import numpy as np\n",
        "import gspread\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "spreadsheet_name = \"EPFL unanotated tweets\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown <br /><br /> Leave the sheet name open if you want to analyse the first sheet in the spreadsheet.\n",
        "sheet_name=\"raw\"#@param {type:\"string\"}\n",
        "\n",
        "#@markdown <br /><br /> The target document needs a column with an ID for every tweet. This ID will be used to link back when creating the Unique tweets\n",
        "ID_column_number=1  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown <br /><br /> Please insert the column number that contains the data that should be checked for duplicates.  The script assumes that the first row is a header, and will not touch this.\n",
        "\n",
        "source_column_number=2  #@param {type:\"integer\"}\n",
        "first_row_header = True\n",
        "##@param {type:\"boolean\"}\n",
        "#@markdown <br /><br /> Other columns that should be carried over into the unique set. This is typically columns with date information, previous completed codings etc. The original value will be passed along. Please note that if you would like to preserve the date from the first post, you should sort the original spreadsheet by date before running this script. The expected input is a comma-separated list of numbers.\n",
        "\n",
        "duplicate_column_numbers=\"\"  #@param {type:\"string\"}\n",
        "\n",
        "if duplicate_column_numbers:\n",
        "  include_columns = duplicate_column_numbers.split(\",\")\n",
        "  include_columns = list(map(int, include_columns)) \n",
        "else:\n",
        "  include_columns = []\n",
        "\n",
        "#Open the spreadsheet\n",
        "try:\n",
        "  spreadsheet = gc.open(spreadsheet_name)\n",
        "  #print(\"Spreadsheet is opened\")\n",
        "except:\n",
        "  print (\"An error occured while trying to open the spreadsheet. Does not seem to be a spreadwheet with this name in your home folder.\")\n",
        "  sys.exit()\n",
        "\n",
        "#Open the worksheet\n",
        "try:\n",
        "  if sheet_name:\n",
        "    worksheet = spreadsheet.worksheet(sheet_name)\n",
        "  else:\n",
        "    worksheet = spreadsheet.get_worksheet(0)\n",
        "  #print(\"Worksheet successfully selected\")\n",
        "\n",
        "except:\n",
        "  print(\"Unable to select worksheet\")\n",
        "  sys.exit()\n",
        "\n",
        "#Get all values\n",
        "values = worksheet.get_all_values()\n",
        "\n",
        "if(len(values) > 0):\n",
        "  print(\"Successfully read \"+str(len(values)-1)+\" items\")\n",
        "  if(first_row_header):\n",
        "    print(\"ID Column Header: \\\"\"+values[0][ID_column_number-1]+\"\\\"\")\n",
        "    print(\"Target Column Header: \\\"\"+values[0][source_column_number-1]+\"\\\"\")\n",
        "    print(\"Target First data row: \\\"\"+values[1][source_column_number-1]+\"\\\"\")\n",
        "    print(\"Also include the following \"+str(len(include_columns))+\" columns: \")\n",
        "    for c in include_columns:\n",
        "      print(\"     \"+values[0][c-1])\n",
        "\n",
        "else:\n",
        "  print(\"No valid posts. Please check the input variables.\")    \n",
        "#@markdown <br /><br /> Do a test run where you just run this cell. Make sure that the input is OK. Running this cell will not alter any data."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZQpKKk088NA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Create Sheet with Unique Tweets\n",
        "!pip install --upgrade --quiet gspread\n",
        "!pip install python-Levenshtein\n",
        "import Levenshtein\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "def reauthenticate():\n",
        "  gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "  spreadsheet = gc.open(spreadsheet_name)\n",
        "  newworksheet = spreadsheet.worksheet(unique_sheet_name)\n",
        "  return newworksheet\n",
        "\n",
        "program_start_time=datetime.now()\n",
        "\n",
        "\n",
        "#Loop through the dataset and find duplicates\n",
        "maxDistance = 10 #@param {type:\"integer\"}\n",
        "#@markdown <br /><br />Adjustment for short texts. Protects short tweets so that Levenshtein-distance is relatively shorter for short tweets. The default setting is \"10\"\n",
        "\n",
        "shortAdjust = 10 #@param {type:\"integer\"}\n",
        "\n",
        "#Set this to 1 to drop headers - default\n",
        "# #@markdown <br /><br />The default value here is \"1\". If the dataset is huge, it might however be necessary to restart the script. Then enter the value where the script should start.\n",
        "\n",
        "start = 1 \n",
        "# #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "#@markdown <br /><br />Set the name of the worksheet where the results will be created\n",
        "unique_sheet_name = \"deduplicated\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "data = pd.DataFrame.from_records(values)\n",
        "data.columns = data.iloc[0]\n",
        "data = data.reindex(data.index.drop(0))\n",
        "\n",
        "try:\n",
        "  newworksheet = spreadsheet.add_worksheet(title=unique_sheet_name, rows=data.shape[0], cols=data.shape[1]+len(include_columns)-1)\n",
        "  print(\"Created new worksheet\")\n",
        "except:\n",
        "  newworksheet = spreadsheet.worksheet(unique_sheet_name)\n",
        "  print(\"Worksheet already created, opening existing worksheet. Starting at the end\")\n",
        "  start = len(newworksheet.get_all_values())-1\n",
        "  if start <= 1:\n",
        "    start = 1\n",
        "\n",
        "\n",
        "end = data.shape[0]\n",
        "\n",
        "#Print headers\n",
        "newworksheet.update_cell(1,1,\"Original ID\")\n",
        "newworksheet.update_cell(1,2,\"DeDupe ID\")\n",
        "newworksheet.update_cell(1,3,\"Duplicate List\")\n",
        "newworksheet.update_cell(1,4,\"Number of Duplicates\")\n",
        "newworksheet.update_cell(1,5,\"Is a duplicate\")\n",
        "y = 6\n",
        "for c in include_columns:\n",
        "  newworksheet.update_cell(1,y,values[0][c-1])\n",
        "  y += 1\n",
        "  \n",
        "newworksheet.update_cell(1,y,values[0][source_column_number-1])\n",
        "\n",
        "for i in range(start,end):\n",
        "  x = data.iloc[i-1,source_column_number-1]\n",
        "  id = data.iloc[i-1,ID_column_number-1]\n",
        "  \n",
        "  print(\"Analyzing #\"+str(i))\n",
        "  isADuplicate = 1\n",
        "  firstpost = 9999999\n",
        "  duplist = []\n",
        "  \n",
        "  for j in range(1,end):\n",
        "    y = data.iloc[j-1,source_column_number-1]\n",
        "    minxy = min(len(x), len(y))\n",
        "    distance = Levenshtein.distance(x, y)\n",
        "    if (x == y) or (distance <= maxDistance and (minxy - (minxy+ shortAdjust)/2)  > distance):\n",
        "      duplist.append(data.iloc[j-1, ID_column_number-1])\n",
        "      if(j-1 < firstpost):\n",
        "        firstpost = j-1\n",
        "\n",
        "\n",
        "\n",
        "  if duplist[0] == id:\n",
        "    isADuplicate = 0\n",
        "    \n",
        "  #Reauthenticate every ten minutes \n",
        "  if datetime.now() > program_start_time + timedelta(minutes=5):\n",
        "    newworksheet = reauthenticate()\n",
        "    program_start_time = datetime.now()   #Resets the Program Start Time\n",
        "    print(\"Reauthenticating at:\" + str(datetime.now()))\n",
        "\n",
        "  cell_values = []\n",
        "  cell_values.append(id)\n",
        "  cell_values.append(firstpost+1)\n",
        "  cell_values.append(str(duplist))\n",
        "  cell_values.append(int(len(duplist)))\n",
        "  cell_values.append(isADuplicate)\n",
        "  \n",
        "  y = 6\n",
        "  for c in include_columns:\n",
        "    print(data.loc[i][c-1])\n",
        "    cell_values.append(data.loc[i][c-1])\n",
        "    y += 1\n",
        "\n",
        "  cell_values.append(x)\n",
        "\n",
        "  cell_list = newworksheet.range(i+1,1,i+1,y)\n",
        "  for p, val in enumerate(cell_values):  #gives us a tuple of an index and value\n",
        "    cell_list[p].value = val    #use the index on cell_list and the val from cell_values\n",
        "\n",
        "  newworksheet.update_cells(cell_list)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}